{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Lab 3\n",
    "\n",
    "The illusion of conversation, and multi-shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from litellm import completion\n",
    "from IPython.display import Markdown, display\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"pydantic.*\")\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hi there!\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "response = completion(model=\"gpt-4.1-mini\", messages=messages)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, George! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"My name is George.\"}\n",
    "]\n",
    "response = completion(model=\"gpt-4.1-mini\", messages=messages)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't have access to your personal information unless you share it with me. What would you like me to call you?\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What's my name?\"}\n",
    "]\n",
    "response = completion(model=\"gpt-4.1-mini\", messages=messages)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your name is George. How can I assist you further, George?\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hi there!\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Hi there! How can I help you today?\"},\n",
    "    {\"role\": \"user\", \"content\": \"My name is George.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Hi George! How can I assist you today?\"},\n",
    "    {\"role\": \"user\", \"content\": \"What's my name?\"}\n",
    "]\n",
    "\n",
    "response = completion(model=\"gpt-4.1-mini\", messages=messages)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation\n",
    "\n",
    "The reason I show you this is to emphasize that every call to the LLM is completely stateless.\n",
    "\n",
    "The sense that we are engaged in a chat with the LLM that takes place over several minutes is an illusion, enabled by the trick of passing in the entire conversation so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input tokens: 65\n",
      "Output tokens: 14\n",
      "Total cost: 0.0048 cents\n"
     ]
    }
   ],
   "source": [
    "# Let's look at the cost - this is the cost of the entire conversation\n",
    "# Any guesses on how much this is?\n",
    "\n",
    "print(f\"Input tokens: {response.usage.prompt_tokens}\")\n",
    "print(f\"Output tokens: {response.usage.completion_tokens}\")\n",
    "print(f\"Total cost: {response._hidden_params[\"response_cost\"]*100:.4f} cents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference time \"training\" with multi-shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The meaning of life is a deeply philosophical question that varies depending on individual beliefs, cultures, and perspectives. Some see it as seeking happiness, fulfilling personal goals, building relationships, or contributing to others. Others find meaning through spirituality, religion, or the pursuit of knowledge. Ultimately, the meaning of life is a personal journey and can be different for each person.\n",
       "\n",
       "El significado de la vida es una pregunta profundamente filosófica que varía según las creencias individuales, las culturas y las perspectivas. Algunos lo ven como la búsqueda de la felicidad, el cumplimiento de metas personales, la construcción de relaciones o la contribución a los demás. Otros encuentran significado a través de la espiritualidad, la religión o la búsqueda del conocimiento. En última instancia, el significado de la vida es un viaje personal y puede ser diferente para cada persona."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a helpful assistant that answers questions in English and then in Spanish.\n",
    "\"\"\"\n",
    "user_prompt = \"What's the meaning of life?\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "]\n",
    "response = completion(model=\"gpt-4.1-mini\", messages=messages)\n",
    "display(Markdown(response.choices[0].message.content))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## My reply in English is:\n",
       "The meaning of life is a profound and philosophical question that has been explored by many cultures and thinkers throughout history. Generally, it can be understood as the pursuit of happiness, purpose, love, knowledge, and fulfillment. Different people and philosophies may have different interpretations, but often it revolves around finding meaning through relationships, personal growth, and contributing to something greater than oneself.\n",
       "\n",
       "## My reply in Spanish is:\n",
       "El significado de la vida es una pregunta profunda y filosófica que ha sido explorada por muchas culturas y pensadores a lo largo de la historia. Generalmente, se puede entender como la búsqueda de la felicidad, el propósito, el amor, el conocimiento y la realización personal. Diferentes personas y filosofías pueden tener interpretaciones distintas, pero a menudo gira en torno a encontrar sentido a través de las relaciones, el crecimiento personal y la contribución a algo más grande que uno mismo."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are a helpful assistant that answers questions in English and then in Spanish.\n",
    "\n",
    "For example, if the user asks 'What is 2+2' then you would answer as follows:\n",
    "\n",
    "## My reply in English is:\n",
    "Four\n",
    "\n",
    "## My reply in Spanish is:\n",
    "Cuatro\n",
    "\n",
    "\"\"\"\n",
    "user_prompt = \"What's the meaning of life?\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": user_prompt}\n",
    "]\n",
    "response = completion(model=\"gpt-4.1-mini\", messages=messages)\n",
    "display(Markdown(response.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Is this \"training\"?\n",
    "\n",
    "It appears that the model _learned_ the format that we wanted, based on the example given.\n",
    "\n",
    "But there was no training going on in the Data Science sense; the trillions of parameters in gpt-4.1-mini weren't changed.\n",
    "\n",
    "It's simply that when predicting the next tokens to come after our question, the model is more likely to predict tokens that would follow the same pattern as the examples in the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
